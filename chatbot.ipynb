{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2077dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('E:\\\\nlp learning\\\\medical entity\\\\The Diseases DataBase (TDDB) Project\\\\The Diseases DataBase (TDDB) Project\\\\Diseases_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases=dataset['name of symptoms-causes']\n",
    "symptoms = dataset['Symptoms']\n",
    "dataset.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ec919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fuzzywuzzy\n",
    "#pip install fuzzywuzzy[speedup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6720f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from scipy import spatial\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fuzz.partial_ratio(\"Sensations of a fast, fluttering or pounding heartbeat (palpitations)\", \"very fast heartbeat (tachycardia) \")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\"chest discomfort or chest pain\", \"very fast heartbeat (tachycardia) \", \"New York Giants\", \"Dallas Cowboys\"]\n",
    "res = process.extract(\"Sensations of a fast, fluttering or pounding heartbeat (palpitations)\", choices)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms2=[]\n",
    "for i in tqdm(range(len(symptoms))):\n",
    "    temp=symptoms[i].split('@$')\n",
    "    symptoms2.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09771f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms3=[]\n",
    "for i in range(len(symptoms2)):\n",
    "    symp=[]\n",
    "    for j in range(len(symptoms2[i])):\n",
    "        if len(symptoms2[i][j]) <= 100 and symptoms2[i][j] !='':\n",
    "            symp.append(symptoms2[i][j])\n",
    "    symptoms3.append(symp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases2=[]\n",
    "symptoms4=[]\n",
    "for i in tqdm(range(len(symptoms3))):\n",
    "    if len(symptoms3[i])>=4:\n",
    "        diseases2.append(diseases[i])\n",
    "        symptoms4.append(symptoms3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47470c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(symptoms4))\n",
    "len(diseases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms5=[]\n",
    "for i in tqdm(range(len(symptoms4))):\n",
    "    for j in range(len(symptoms4[i])):\n",
    "        for x in symptoms5:\n",
    "            res = fuzz.partial_ratio(symptoms4[i][j], x)\n",
    "            if res>=90:\n",
    "                symptoms4[i][j]=x\n",
    "        symptoms5.append(symptoms4[i][j].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe854fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symptoms4.pkl', 'rb') as f:\n",
    "    symptoms4 = pickle.load(f)\n",
    "\n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symptoms5.pkl', 'rb') as f:\n",
    "    symptoms5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms5[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(symptoms5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms6=sorted(set(symptoms5), key=symptoms5.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(symptoms6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc12368",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms6[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db39db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms6.append('disease')\n",
    "df = pd.DataFrame(columns = symptoms6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a30667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(symptoms4)):\n",
    "    temp=[0] * len(symptoms6)\n",
    "    indx=[]\n",
    "    for j in range(len(symptoms4[i])):\n",
    "        indx.append(symptoms6.index(symptoms4[i][j].lower()))\n",
    "        temp[symptoms6.index(symptoms4[i][j].lower())]=1\n",
    "    temp[len(symptoms6)-1]=diseases2[i]\n",
    "    #print(i)\n",
    "    df.loc[len(df)] = temp\n",
    "    for x in indx:\n",
    "        temp[x]=0\n",
    "        df.loc[len(df)] = temp\n",
    "        temp[x]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5821 rows Ã— 3253 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"E:\\\\nlp learning\\\\HC\\\\models\\\\allDis2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b697b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(df.columns[df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)\n",
    "df.dropna(how='all', axis='columns')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d574a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "symp=list(df.iloc[0:0,1:3083])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbcb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "symp[len(symp)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "li=list(df['disease'])\n",
    "dis = sorted(set(li), key=li.index)\n",
    "len(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f315d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[]\n",
    "\n",
    "for i in range(0,len(symp)):\n",
    "    l2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the values in the imported file by pandas by the inbuilt function replace in pandas.\n",
    "for i in range(len(dis)):\n",
    "    df.replace({'disease':{dis[i]:i}},inplace=True)\n",
    "\n",
    "#check the df \n",
    "#df.head(20)\n",
    "\n",
    "X= df[symp]\n",
    "\n",
    "#X.head(10)\n",
    "\n",
    "y = df[[\"disease\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fea548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,classification_report, accuracy_score\n",
    "def DecisionTree():\n",
    "    clf3 = tree.DecisionTreeClassifier() \n",
    "    clf3 = clf3.fit(X_train,np.ravel(y_train))\n",
    "    '''\n",
    "    # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\DecisionTree.sav'\n",
    "    pickle.dump(clf3, open(filename, 'wb'))\n",
    "    '''\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred=clf3.predict(X_test)\n",
    "    print(clf3)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    '''\n",
    "    psymptoms = [symp[1]]\n",
    "\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "    inputtest = [l2]\n",
    "    predict = clf3.predict(inputtest)\n",
    "    probs = clf3.predict_proba(inputtest)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    print(best_n)\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predict)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    predicted=predict[0]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    print(dis[predicted])\n",
    "    '''\n",
    "DecisionTree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest():\n",
    "    clf4 = RandomForestClassifier(criterion='entropy',n_estimators=100,min_samples_split=10,min_samples_leaf=1)\n",
    "    clf4 = clf4.fit(X_train,np.ravel(y_train))\n",
    "    print(clf4)\n",
    "    '''\n",
    "    # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\RandomForest.sav'\n",
    "    pickle.dump(clf4, open(filename, 'wb'))\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # calculating accuracy \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred=clf4.predict(X_test)\n",
    "    \n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    '''\n",
    "    psymptoms = [symp[1]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = clf4.predict(inputtest)\n",
    "    probs = clf4.predict_proba(inputtest)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    print(best_n)\n",
    "    predicted=predict[0]\n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "    '''\n",
    "randomforest()       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4741b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    gnb = GaussianNB()\n",
    "    gnb=gnb.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\NaiveBayes.sav'\n",
    "    pickle.dump(gnb, open(filename, 'wb'))\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred=gnb.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    psymptoms = [symp[1]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = gnb.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = gnb.predict_proba(inputtest)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    print(best_n)\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "    \n",
    "        \n",
    "NaiveBayes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e05d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "def LR():\n",
    "    logreg = LogisticRegression(solver='liblinear', C=0.05)\n",
    "    model=logreg.fit(X_train,np.ravel(y_train))\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    '''\n",
    "        # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\LogReg.sav'\n",
    "    pickle.dump(logreg, open(filename, 'wb'))\n",
    "    \n",
    "    \n",
    "    psymptoms = [symp[1]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = model.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = model.predict_proba(inputtest)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    print(best_n)\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "    '''\n",
    "        \n",
    "LR()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "def SVM():\n",
    "    svm = SVC(probability=True,C=5)\n",
    "    model=svm.fit(X_train,np.ravel(y_train))\n",
    "    \n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\SVM.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    psymptoms = [symp[1]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = model.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = model.predict_proba(inputtest)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    print(best_n)\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "        \n",
    "SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB():\n",
    "    # Multinomial NB Classifier\n",
    "    mnb = MultinomialNB()\n",
    "    mnb = mnb.fit(X_train,np.ravel(y_train))\n",
    "    # prediction of labels for the test data\n",
    "     # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\mnb.sav'\n",
    "    pickle.dump(mnb, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred=mnb.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    psymptoms = [symp[0],symp[1]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = mnb.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = mnb.predict_proba(inputtest)\n",
    "    #best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    best_n = np.argsort(-probs, axis=1)\n",
    "    best_n2 = -np.sort(-probs, axis=1)\n",
    "    print(best_n)\n",
    "    print(best_n2)\n",
    "    newDis=[]\n",
    "    for i in range(len(best_n[0])):\n",
    "        x=round(best_n2[0][i]*1000)\n",
    "        if(x>=1):\n",
    "            newDis.append(best_n[0][i])\n",
    "\n",
    "    print(newDis)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "MNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    # KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=7, weights='distance', n_jobs=4)\n",
    "    knn = knn.fit(X_train,np.ravel(y_train))\n",
    "     # prediction of labels for the test data\n",
    "     # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\knn.sav'\n",
    "    pickle.dump(knn, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred=knn.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    psymptoms = [symp[100]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = knn.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = knn.predict_proba(inputtest)\n",
    "    #best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    best_n = np.argsort(-probs, axis=1)\n",
    "    best_n2 = -np.sort(-probs, axis=1)\n",
    "    print(best_n)\n",
    "    print(best_n2)\n",
    "    newDis=[]\n",
    "    for i in range(len(best_n[0])):\n",
    "        x=round(best_n2[0][i]*1000)\n",
    "        if(x>=1):\n",
    "            newDis.append(best_n[0][i])\n",
    "\n",
    "    print(newDis)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP():\n",
    "    # MLP Classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(32, 32, 32), activation='relu', solver='adam', max_iter=50)\n",
    "    mlp = mlp.fit(X_train,np.ravel(y_train))\n",
    "     # prediction of labels for the test data\n",
    "     # save the model to disk\n",
    "    filename = 'E:\\\\nlp learning\\\\HC\\\\models\\\\mlp.sav'\n",
    "    pickle.dump(mlp, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred=mlp.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    psymptoms = [symp[0]]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(psymptoms)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "\n",
    "    inputtest = [l2]\n",
    "    predict = mlp.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = mlp.predict_proba(inputtest)\n",
    "    #best_n = np.argsort(probs, axis=1)[:,-5:]\n",
    "    best_n = np.argsort(-probs, axis=1)\n",
    "    best_n2 = -np.sort(-probs, axis=1)\n",
    "    print(best_n)\n",
    "    print(best_n2)\n",
    "    newDis=[]\n",
    "    for i in range(len(best_n[0])):\n",
    "        x=round(best_n2[0][i]*1000)\n",
    "        if(x>=1):\n",
    "            newDis.append(best_n[0][i])\n",
    "\n",
    "    print(newDis)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print(predicted)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "\n",
    "    print(dis[predicted])\n",
    "MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[dis[108]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07454627",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symp.pkl', 'wb') as f:\n",
    "    pickle.dump(symp, f)\n",
    "    \n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\dis.pkl', 'wb') as f:\n",
    "    pickle.dump(dis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symptoms4.pkl', 'wb') as f:\n",
    "    pickle.dump(symptoms4, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "svm = 'E:\\\\nlp learning\\\\HC\\\\models\\\\SVM.sav'\n",
    "dt = 'E:\\\\nlp learning\\\\HC\\\\models\\\\DecisionTree.sav'\n",
    "logreg = 'E:\\\\nlp learning\\\\HC\\\\models\\\\LogReg.sav'\n",
    "nb = 'E:\\\\nlp learning\\\\HC\\\\models\\\\NaiveBayes.sav'\n",
    "rf = 'E:\\\\nlp learning\\\\HC\\\\models\\\\RandomForest.sav'\n",
    "mnb = 'E:\\\\nlp learning\\\\HC\\\\models\\\\mnb.sav'\n",
    "knn = 'E:\\\\nlp learning\\\\HC\\\\models\\\\knn.sav'\n",
    "mlp = 'E:\\\\nlp learning\\\\HC\\\\models\\\\mlp.sav'\n",
    "SVM = pickle.load(open(svm, 'rb'))\n",
    "DT = pickle.load(open(dt, 'rb'))\n",
    "LogReg = pickle.load(open(logreg, 'rb'))\n",
    "RF = pickle.load(open(rf, 'rb'))\n",
    "NB = pickle.load(open(nb, 'rb'))\n",
    "MNB = pickle.load(open(mnb, 'rb'))\n",
    "KNN = pickle.load(open(knn, 'rb'))\n",
    "MLP = pickle.load(open(mlp, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the lists from disk\n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symp.pkl', 'rb') as f:\n",
    "    symp = pickle.load(f)\n",
    "\n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\dis.pkl', 'rb') as f:\n",
    "    dis = pickle.load(f)\n",
    "    \n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symptoms4.pkl', 'rb') as f:\n",
    "    symptoms4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd89b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRes(model,psymptoms,symp):\n",
    "    l2=[]\n",
    "    for i in range(0,len(symp)):\n",
    "        l2.append(0)\n",
    "    for k in range(0,len(symp)):\n",
    "        for z in psymptoms:\n",
    "            if(z==symp[k]):\n",
    "                l2[k]=1\n",
    "    inputtest = [l2]\n",
    "    predict = model.predict(inputtest)\n",
    "    predicted=predict[0]\n",
    "    probs = model.predict_proba(inputtest)\n",
    "    best_n = np.argsort(-probs, axis=1)\n",
    "    best_n2 = -np.sort(-probs, axis=1)\n",
    "    #print(best_n)\n",
    "    #print(best_n2[0])\n",
    "\n",
    "    newDis = []\n",
    "\n",
    "    for i in range(len(best_n[0])):\n",
    "        x=round(best_n2[0][i]*100)\n",
    "        if(x>=1):\n",
    "            newDis.append(best_n[0][i])\n",
    "\n",
    "    return newDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31799aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "psymptoms = [symp[1],symp[2]]\n",
    "newDis = getRes(NB,psymptoms,symp)\n",
    "print(newDis)\n",
    "symp[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[dis[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb313950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disPrediction():\n",
    "    x=0\n",
    "    psymptoms=[]\n",
    "    allS=[]\n",
    "    allS2=[]\n",
    "    indx=0\n",
    "    sym=''\n",
    "    flag=False\n",
    "    refused = []\n",
    "    while True:\n",
    "        if flag:\n",
    "            break\n",
    "        if x==0:\n",
    "            x=x+1\n",
    "            sym=input('enter symptoms ')\n",
    "            psymptoms.append(sym)\n",
    "            newDis = getRes(MLP,psymptoms,symp)\n",
    "            #print(\"num dis \",newDis)\n",
    "            for i in newDis:\n",
    "                if sym.capitalize() in symptoms4[i]:\n",
    "                    allS.append(symptoms4[i])\n",
    "            for i in range(len(allS)):\n",
    "                for j in range(len(allS[i])):\n",
    "                    allS2.append(allS[i][j].lower())\n",
    "            random.shuffle(allS2)\n",
    "        else:\n",
    "            #print(allS2)\n",
    "            if allS2[indx] not in psymptoms and allS2[indx] not in refused:\n",
    "                sym2=input('do you suffer from '+allS2[indx]+\" please answer with yes or no?\")\n",
    "                if sym2=='yes':\n",
    "                    psymptoms.append(allS2[indx])\n",
    "                    newDis = getRes(MLP,psymptoms,symp)\n",
    "                    #print(\"num dis \",newDis)\n",
    "                    allS=[]\n",
    "                    allS2=[]\n",
    "                    indx=0\n",
    "                    for i in newDis:\n",
    "                        if sym.capitalize() in symptoms4[i]:\n",
    "                            allS.append(symptoms4[i])\n",
    "                    for i in range(len(allS)):\n",
    "                        for j in range(len(allS[i])):\n",
    "                            allS2.append(allS[i][j].lower())\n",
    "                    random.shuffle(allS2)\n",
    "                        #and((len(symptoms4[i])/len(psymptoms))*100>=80)\n",
    "                    m=0\n",
    "                    for i in psymptoms:\n",
    "                        if i.capitalize() in symptoms4[newDis[0]]:\n",
    "                            m=m+1\n",
    "                    print(\"acc \",m/len(symptoms4[newDis[0]])*100)\n",
    "                    acc=(m/len(symptoms4[newDis[0]]))\n",
    "                    if acc*100 >=70:\n",
    "                        print('you are suffer from ',dis[newDis[0]],'with acc ',acc)\n",
    "                        flag=True\n",
    "                        break\n",
    "                    else:\n",
    "                        print(symptoms4[newDis[0]],\"     \",psymptoms)\n",
    "                else :\n",
    "                    refused.append(allS2[indx])\n",
    "            indx = indx+1\n",
    "            continue\n",
    "\n",
    "    ['Sensations of a fast, fluttering or pounding heartbeat (palpitations)',\n",
    " 'Chest pain',\n",
    " 'Dizziness',\n",
    " 'Fatigue',\n",
    " 'Lightheadedness',\n",
    " 'Reduced ability to exercise',\n",
    " 'Shortness of breath',\n",
    " 'Weakness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad8a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb01c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diseasePrediction2():\n",
    "    x=0\n",
    "    psymptoms=[]\n",
    "    allS=[]\n",
    "    allS2=[]\n",
    "    indx=0\n",
    "    sym=''\n",
    "    flag=False\n",
    "    refused = []\n",
    "\n",
    "\n",
    "    while True:\n",
    "        if flag:\n",
    "            break\n",
    "        if x==0:\n",
    "            x=x+1\n",
    "            sym=input('enter symptoms ')\n",
    "            psymptoms.append(sym)\n",
    "            newDis = getRes(MLP,psymptoms,symp)\n",
    "            #print(\"num dis \",newDis)\n",
    "            for i in newDis:\n",
    "                if sym.capitalize() in symptoms4[i]:\n",
    "                    allS.append(symptoms4[i])\n",
    "            for i in range(len(allS)):\n",
    "                for j in range(len(allS[i])):\n",
    "                    allS2.append(allS[i][j].lower())\n",
    "            random.shuffle(allS2)\n",
    "        else:\n",
    "            #print(allS2)\n",
    "            if indx<len(allS2) and allS2[indx] not in psymptoms and allS2[indx] not in refused:\n",
    "                sym2=input('do you suffer from '+allS2[indx]+\" please answer with yes or no?\")\n",
    "                if sym2=='yes':\n",
    "                    psymptoms.append(allS2[indx])\n",
    "                    newDis = getRes(MLP,psymptoms,symp)\n",
    "                    #print(\"num dis \",newDis)\n",
    "                    allS=[]\n",
    "                    allS2=[]\n",
    "                    indx=0\n",
    "                    for i in newDis:\n",
    "                        if sym.capitalize() in symptoms4[i]:\n",
    "                            allS.append(symptoms4[i])\n",
    "                    for i in range(len(allS)):\n",
    "                        for j in range(len(allS[i])):\n",
    "                            allS2.append(allS[i][j].lower())\n",
    "                    random.shuffle(allS2)\n",
    "                        #and((len(symptoms4[i])/len(psymptoms))*100>=80)\n",
    "                    m=0\n",
    "                    for i in psymptoms:\n",
    "                        if i.capitalize() in symptoms4[newDis[0]]:\n",
    "                            m=m+1\n",
    "                    #print(\"acc \",m/len(symptoms4[newDis[0]])*100)\n",
    "                    acc=(m/len(symptoms4[newDis[0]]))\n",
    "                    if acc*100 >=70:\n",
    "                        print('you are suffer from ',dis[newDis[0]],'with acc ',acc)\n",
    "                        m=0\n",
    "                        for i in psymptoms:\n",
    "                            if i.capitalize() in symptoms4[newDis[1]]:\n",
    "                                m=m+1\n",
    "                        acc=(m/len(symptoms4[newDis[1]]))\n",
    "                        print('you are suffer from ',dis[newDis[1]],'with acc ',acc)\n",
    "\n",
    "                        m=0\n",
    "                        for i in psymptoms:\n",
    "                            if i.capitalize() in symptoms4[newDis[2]]:\n",
    "                                m=m+1\n",
    "                        acc=(m/len(symptoms4[newDis[2]]))\n",
    "                        print('you are suffer from ',dis[newDis[2]],'with acc ',acc)\n",
    "\n",
    "                        flag=True\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"len  \",len(allS2),symptoms4[newDis[0]],\"     \",psymptoms)\n",
    "                else :\n",
    "                    refused.append(allS2[indx])\n",
    "            indx = indx+1\n",
    "            continue\n",
    "\n",
    "    ['Sensations of a fast, fluttering or pounding heartbeat (palpitations)',\n",
    " 'Chest pain',\n",
    " 'Dizziness',\n",
    " 'Fatigue',\n",
    " 'Lightheadedness',\n",
    " 'Reduced ability to exercise',\n",
    " 'Shortness of breath',\n",
    " 'Weakness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb951ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9bcab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\nlp learning\\\\HC\\\\models\\\\dialog.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab445d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(df.columns)\n",
    "a = a.rename({0: df.columns[0],1: df.columns[1]})\n",
    "df = df.append(a,ignore_index=True)\n",
    "df.columns=['Questions','Answers']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.index[0:3725], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('E:\\\\nlp learning\\\\HC\\\\models\\\\aid.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "aid = json.load(f)\n",
    "  \n",
    "# Iterating through the json\n",
    "# list\n",
    "dic = {}\n",
    "for i in aid['intents']:\n",
    "    qu=i['patterns']\n",
    "    ans=i['responses']\n",
    "    for j in qu:\n",
    "        dic['Questions']=j\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        qu='can you help me i have a '+i['tag']+'?'\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "        qu=\"please help i have  \"+i['tag']+'?'\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"oooh nooo i injured with \"+i['tag']+' can you help me please'+'?'\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df[4390:4460].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {'Questions':'Hi','Answers':'hello'}\n",
    "c = {'Questions':'Hello','Answers':'hi'}\n",
    "d= {'Questions':'how are you','Answers':\"i'm fine. how about yourself?\"}\n",
    "e= {'Questions':'how are you doing','Answers':\"i'm fine. how about yourself?\"}\n",
    "f= {'Questions':'what is your name','Answers':\"my name is Dr-Care\"}\n",
    "g= {'Questions':'how old are you','Answers':\"i am just a bot and my age is the year that i was created in\"}\n",
    "h= {'Questions':'what is your age','Answers':\"i am just a bot and my age is the year that i was created in\"}\n",
    "i= {'Questions':'what should I call you','Answers':\"my name is Dr-Care\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ddb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append([b,c,d,e,f,g,h,i],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(c,ignore_index=True)\n",
    "df = df.append(d,ignore_index=True)\n",
    "df = df.append(d,ignore_index=True)\n",
    "df = df.append(e,ignore_index=True)\n",
    "df = df.append(e,ignore_index=True)\n",
    "df = df.append(f,ignore_index=True)\n",
    "df = df.append(f,ignore_index=True)\n",
    "df = df.append(g,ignore_index=True)\n",
    "df = df.append(g,ignore_index=True)\n",
    "df = df.append(h,ignore_index=True)\n",
    "df = df.append(h,ignore_index=True)\n",
    "df = df.append(i,ignore_index=True)\n",
    "df = df.append(i,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c22d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df2 = pd.read_excel(\"E:\\\\nlp learning\\\\HC\\\\models\\\\Medicine_description.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da58fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d29a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reason=list(df2['Reason'])\n",
    "uniq=sorted(set(Reason), key=Reason.index)\n",
    "topics = {}\n",
    "for i in tqdm(uniq):\n",
    "    topics[i]=df2[df2['Reason']==i]\n",
    "len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[uniq[0]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic1 = {}\n",
    "dic2= {}\n",
    "dic3 = {}\n",
    "dic4 = {}\n",
    "dic5 = {}\n",
    "dic6 = {}\n",
    "dic7 = {}\n",
    "dic8 = {}\n",
    "dic9 = {}\n",
    "dic10 = {}\n",
    "dic11 = {}\n",
    "dic12 = {}\n",
    "dic13 = {}\n",
    "dic14 = {}\n",
    "for i in tqdm(uniq):\n",
    "    Drug_Name = list(topics[i]['Drug_Name'])\n",
    "    Description =list(topics[i]['Description'])\n",
    "    qu = 'can you recommend me a cure for '+i\n",
    "    ans=\"\"\n",
    "    for j in range(len(Drug_Name)):\n",
    "        if pd.isna(Description[j]):\n",
    "            ans += str(j)+\"- \"+Drug_Name[j]+\" is used for \"+ 'healing '+i+\"\\n\"\n",
    "        else:\n",
    "            ans += str(j)+\"- \"+Drug_Name[j]+\" is used for \"+ Description[j]+\"\\n\"\n",
    "    dic['Questions']=qu\n",
    "    dic['Answers']=ans\n",
    "    qu = 'can you recommend me a drugs for '+i\n",
    "    dic1['Questions']=qu\n",
    "    dic1['Answers']=ans\n",
    "    qu = 'what is the treatment for '+i\n",
    "    dic2['Questions']=qu\n",
    "    dic2['Answers']=ans\n",
    "    qu = 'Which treatment is most common for '+i\n",
    "    dic3['Questions']=qu\n",
    "    dic3['Answers']=ans\n",
    "    qu = i+' what is the drugs for this disease '\n",
    "    dic4['Questions']=qu\n",
    "    dic4['Answers']=ans\n",
    "    qu = i+' what is the treatment for this disease '\n",
    "    dic5['Questions']=qu\n",
    "    dic5['Answers']=ans\n",
    "    df = df.append([dic,dic1,dic2,dic3,dic4,dic5],ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aac9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ae298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df2.Drug_Name.unique())} unique groups')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df2.Drug_Name.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df2.Drug_Name.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='y')\n",
    "plt.title('top 10 counts Drugs')\n",
    "plt.xticks(rotation=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c38227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df2.Reason.unique())} unique groups')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df2.Reason.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df2.Reason.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='r')\n",
    "plt.title('top 10 counts Reson')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df2.Description.unique())} unique names')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df2.Description.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df2.Description.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='b')\n",
    "plt.title('top 10 counts Description')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugName = list(df2['Drug_Name'])\n",
    "drugReason = list(df2['Reason'])\n",
    "drugDesc = list(df2['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86222397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "if math. isnan(drugDesc[952] ):\n",
    "    print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic = {}\n",
    "for i in range(len(drugName)):\n",
    "    if  not pd.isna(drugDesc[i]):\n",
    "        qu='can you tell me information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='can you tell me information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"I'd like to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"I'd like to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"I'd like to know information about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+drugReason[i]+\" and is used for \"+drugDesc[i]\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"I'd like to know information about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='Do you know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='Do you know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='Do you know anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='Do you know anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=\" Have you any idea about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\" Have you any idea about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"Do you happen to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=' Would you happen to know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='I wonder if you could tell me anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        qu='tell me information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='tell me information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='i want to know about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='i want to know about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=drugName[i]+\" do you know anything about this cure\"+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=res[0]+\" do you know anything about this cure\"+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"Do you happen to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=' Would you happen to know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='I wonder if you could tell me anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])+\" and is used for \"+str(drugDesc[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        qu='can you tell me information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='can you tell me information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"I'd like to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"I'd like to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"I'd like to know information about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+drugReason[i]\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"I'd like to know information about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='Do you know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='Do you know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='Do you know anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='Do you know anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=\" Have you any idea about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\" Have you any idea about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"Do you happen to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=' Would you happen to know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=' '.join(ans)\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='I wonder if you could tell me anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        qu='tell me information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='tell me information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='i want to know about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='i want to know about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=drugName[i]+\" do you know anything about this cure\"+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=res[0]+\" do you know anything about this cure\"+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "        qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=\"Do you happen to know anything about \"+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu=' Would you happen to know information about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n",
    "        res=re.split(r'(\\d+)', drugName[i]) \n",
    "        qu='I wonder if you could tell me anything about '+res[0]+'?'\n",
    "        ans= drugName[i]+\" is used for \"+str(drugReason[i])\n",
    "        dic['Questions']=qu\n",
    "        dic['Answers']=ans\n",
    "        df = df.append(dic,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/mpwolke/medicine-recommendation/data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfa4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Questions'][32423])\n",
    "df['Answers'][32423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589be8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugReason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e4b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9023cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0718e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset?\n",
    "df3 = pd.read_csv(\"E:\\\\nlp learning\\\\HC\\\\models\\\\drugsComTrain_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd45868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eee756",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df3['condition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741549a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df3.drugName.unique())} unique groups')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df3.drugName.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df3.drugName.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='y')\n",
    "plt.title('top 10 counts drugName')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df3.condition.unique())} unique groups')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df3.condition.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df3.condition.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='r')\n",
    "plt.title('top 10 counts condition')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ce81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset has {len(df3.review.unique())} unique names')\n",
    "print('*'*20)\n",
    "print(f'And the top 10 counts are :')\n",
    "print(df3.review.value_counts().head(10))\n",
    "print('*'*20)\n",
    "\n",
    "c = df3.review.value_counts().head(10)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.bar(c.index, c.values, width=0.8, color='b')\n",
    "plt.title('top 10 counts review')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "drugName = list(df3['drugName'])\n",
    "drugCondition = list(df3['condition'])\n",
    "drugÙŒeview = list(df3['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugÙŒeview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9adc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65867079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic = {}\n",
    "dic1 = {}\n",
    "dic2= {}\n",
    "dic3 = {}\n",
    "dic4 = {}\n",
    "dic5 = {}\n",
    "dic6 = {}\n",
    "dic7 = {}\n",
    "dic8 = {}\n",
    "dic9 = {}\n",
    "dic10 = {}\n",
    "dic11 = {}\n",
    "dic12 = {}\n",
    "dic13 = {}\n",
    "dic14 = {}\n",
    "\n",
    "for i in tqdm(range(len(drugName))):\n",
    "    qu='can you tell me information about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic['Questions']=qu\n",
    "    dic['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    qu=\"I'd like to know anything about \"+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic1['Questions']=qu\n",
    "    dic1['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\"I'd like to know information about \"+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic2['Questions']=qu\n",
    "    dic2['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='Do you know information about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic3['Questions']=qu\n",
    "    dic3['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='Do you know anything about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic4['Questions']=qu\n",
    "    dic4['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\" Have you any idea about \"+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic5['Questions']=qu\n",
    "    dic5['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic6['Questions']=qu\n",
    "    dic6['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic7['Questions']=qu\n",
    "    dic7['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic8['Questions']=qu\n",
    "    dic8['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    qu='tell me information about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic9['Questions']=qu\n",
    "    dic9['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='i want to know about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic10['Questions']=qu\n",
    "    dic10['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=drugName[i]+\" do you know anything about this cure\"+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic11['Questions']=qu\n",
    "    dic11['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\"Do you happen to know anything about \"+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic12['Questions']=qu\n",
    "    dic12['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=' Would you happen to know information about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic13['Questions']=qu\n",
    "    dic13['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='I wonder if you could tell me anything about '+drugName[i]+'?'\n",
    "    ans= drugName[i]+\" is used for \"+str(drugCondition[i])+\" and this is a review from user : \"+str(drugÙŒeview[i])\n",
    "    dic14['Questions']=qu\n",
    "    dic14['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    df = df.append([dic,dic1,dic2,dic3,dic4,dic5,dic6,dic7,dic8,dic9,dic10,dic11,dic12,dic13,dic14],ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0794641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38cf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f7c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254d22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask about disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"E:\\\\nlp learning\\\\medical entity\\\\The Diseases DataBase (TDDB) Project\\\\The Diseases DataBase (TDDB) Project\\\\Diseases_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7df47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = dataset['name of symptoms-causes']\n",
    "overview = dataset['Overview']\n",
    "pragraphOfSymptoms=dataset['pragraph of Symptoms']\n",
    "WhenToSeeADoctor = dataset['When to see a doctor']\n",
    "pragraphOfCauses = dataset['pragraph of Causes']\n",
    "pragraphOfRiskFactors=dataset['pragraph of Risk factors']\n",
    "pragraphOfDiagnosis=dataset['pragraph of Diagnosis']\n",
    "pragraphOfTreatment=dataset['pragraph of Treatment']\n",
    "url_of_disease=dataset['url_of_disease (diagnosis-treatment)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pragraphOfSymptoms[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(overview[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(WhenToSeeADoctor[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(pragraphOfCauses[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(pragraphOfRiskFactors[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(pragraphOfDiagnosis[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(pragraphOfTreatment[0].split('@$'))\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(url_of_disease[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe39668",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "dic1={}\n",
    "dic2={}\n",
    "dic3={}\n",
    "dic4={}\n",
    "dic5={}\n",
    "dic6={}\n",
    "dic7={}\n",
    "dic8={}\n",
    "dic9={}\n",
    "dic10={}\n",
    "dic11={}\n",
    "dic12={}\n",
    "dic13={}\n",
    "dic14={}\n",
    "dic15={}\n",
    "dic16={}\n",
    "dic17={}\n",
    "dic18={}\n",
    "dic19={}\n",
    "dic20={}\n",
    "dic21={}\n",
    "dic22={}\n",
    "dic23={}\n",
    "\n",
    "for i in tqdm(range(len(diseases))):\n",
    "    qu='can you tell me information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic['Questions']=qu\n",
    "    dic['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    qu=\"I'd like to know anything about \"+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic1['Questions']=qu\n",
    "    dic1['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\"I'd like to know information about \"+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic2['Questions']=qu\n",
    "    dic2['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='Do you know information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic3['Questions']=qu\n",
    "    dic3['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='Do you know anything about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic4['Questions']=qu\n",
    "    dic4['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\" Have you any idea about \"+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic5['Questions']=qu\n",
    "    dic5['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=\"Do you happen to know anything about \"+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic6['Questions']=qu\n",
    "    dic6['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=' Would you happen to know information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic7['Questions']=qu\n",
    "    dic7['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='I wonder if you could tell me anything about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic8['Questions']=qu\n",
    "    dic8['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    qu='tell me information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic9['Questions']=qu\n",
    "    dic9['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='i want to know about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic10['Questions']=qu\n",
    "    dic10['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=diseases[i]+\" do you know anything about this cure\"+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic11['Questions']=qu\n",
    "    dic11['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "    qu=\"Do you happen to know anything about \"+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic12['Questions']=qu\n",
    "    dic12['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu=' Would you happen to know information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic13['Questions']=qu\n",
    "    dic13['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    qu='I wonder if you could tell me anything about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic14['Questions']=qu\n",
    "    dic14['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    qu = 'tell me information about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic15['Questions']=qu\n",
    "    dic15['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = 'i want to know about '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic16['Questions']=qu\n",
    "    dic16['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    qu = diseases[i]+' do you know anything about this disease'+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic17['Questions']=qu\n",
    "    dic17['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = 'what is the symptoms of '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic18['Questions']=qu\n",
    "    dic18['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    qu = 'do you know the symptoms of '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic19['Questions']=qu\n",
    "    dic19['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = 'what is the cure for '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic20['Questions']=qu\n",
    "    dic20['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    qu = 'do you know the cure of '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic21['Questions']=qu\n",
    "    dic21['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = 'what is the treatment for '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic22['Questions']=qu\n",
    "    dic22['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = 'do you know the treatment of '+diseases[i]+'?'\n",
    "    ans= 'overview:\\n'+'\\n'.join(overview[i].split('@$'))+'\\n'+'Symptoms:\\n'+'\\n'.join(pragraphOfSymptoms[i].split('@$'))+'\\n'+\"When To See A Doctor:\\n\"+'\\n'.join(WhenToSeeADoctor[i].split('@$'))+'\\n'+'Causes:\\n'+'\\n'.join(pragraphOfCauses[i].split('@$'))+'\\n'+'Risk Factors:\\n'+'\\n'.join(pragraphOfRiskFactors[i].split('@$'))+'\\n'+'Diagnosis:\\n'+'\\n'.join(pragraphOfDiagnosis[i].split('@$'))+'\\n'+'Treatment:\\n'+'\\n'.join(pragraphOfTreatment[i].split('@$'))+'\\n'+'url of disease:\\n'+url_of_disease[i]\n",
    "    dic23['Questions']=qu\n",
    "    dic23['Answers']=ans\n",
    "    #df = df.append(dic,ignore_index=True)\n",
    "    \n",
    "    df = df.append([dic,dic1,dic2,dic3,dic4,dic5,dic6,dic7,dic8,dic9,dic10,dic11,dic12,dic13,dic14,dic15,dic16,dic17,dic18,dic19,dic20,dic21,dic22,dic23],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53659732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ee3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Questions'][19700])\n",
    "#print('-----------------------------------------------------------------')\n",
    "#print(df['Answers'][19700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be968d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('E:\\\\nlp learning\\\\HC\\\\models\\\\withoutTreatment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cleaner(x):\n",
    "#    return [a for a in (''.join([a for a in x if a not in string.punctuation])).lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a87609",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('classifier',DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e835ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(query):\n",
    "    return(lemmatizer.lemmatize(query))\n",
    "    \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Questions2'] = df['Questions'].apply(lem)\n",
    "\n",
    "#df['Questions2'] = df['Questions'].apply(cleanText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94393f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe.fit(df['Questions2'],df['Answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # save the model to disk\n",
    "filename = 'E:\\\\nlp learning\\\\HC\\\\models3\\\\withTreatment2.pkl'\n",
    "joblib.dump(Pipe, filename,compress =9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe2=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee03c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalChat(text):\n",
    "    qu = lem(text)\n",
    "    return 'bot: '+Pipe2.predict([qu])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c03bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalChat('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    qu = input('user:' )\n",
    "    if(qu=='exit'):\n",
    "        break\n",
    "    qu = lem(qu)\n",
    "    print('bot: ',Pipe.predict([qu]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "symp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af491435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict first symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the lists from disk\n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\symp.pkl', 'rb') as f:\n",
    "    symp = pickle.load(f)\n",
    "\n",
    "with open('E:\\\\nlp learning\\\\HC\\\\models\\\\intents.json', 'r') as f:\n",
    "    intents = json.load(f)\n",
    "    \n",
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "dic={}\n",
    "\n",
    "for intent in tqdm(intents['intents']):\n",
    "    tag = intent['tag'].lower()\n",
    "    #tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        dic['Questions']=pattern\n",
    "        dic['Answers']=tag\n",
    "        df=df.append(dic,ignore_index=True)\n",
    "        #w = nltk.word_tokenize(pattern)\n",
    "        #all_words.extend(w)\n",
    "        #xy.append( (w, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "dic1={}\n",
    "dic2={}\n",
    "dic3={}\n",
    "dic4={}\n",
    "\n",
    "for i in tqdm(symp):\n",
    "    qu = 'i have '+i\n",
    "    dic['Questions']=qu\n",
    "    dic['Answers']=i\n",
    "    \n",
    "    qu = \"i'm suffer from \"+i\n",
    "    qu = 'i have '+i\n",
    "    dic1['Questions']=qu\n",
    "    dic1['Answers']=i\n",
    "    #df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    qu = \"my symptom is \"+i\n",
    "    qu = 'i have '+i\n",
    "    dic2['Questions']=qu\n",
    "    dic2['Answers']=i\n",
    "    #df.append(dic,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    qu = i+\" is what i feel\"\n",
    "    qu = 'i have '+i\n",
    "    dic3['Questions']=qu\n",
    "    dic3['Answers']=i\n",
    "    #df.append(dic,ignore_index=True)\n",
    "    \n",
    "    qu = \"i feel \"+i\n",
    "    qu = 'i have '+i\n",
    "    dic4['Questions']=qu\n",
    "    dic4['Answers']=i\n",
    "    df = df.append([dic,dic1,dic2,dic3,dic4],ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a699fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('E:\\\\nlp learning\\\\HC\\\\models3\\\\QandAwithTreatment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee87a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>what school do you go to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68141</th>\n",
       "      <td>68141</td>\n",
       "      <td>i have fatigue or a general feeling of discomfort</td>\n",
       "      <td>fatigue or a general feeling of discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68142</th>\n",
       "      <td>68142</td>\n",
       "      <td>i have fatigue or a general feeling of discomfort</td>\n",
       "      <td>fatigue or a general feeling of discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68143</th>\n",
       "      <td>68143</td>\n",
       "      <td>i have fatigue or a general feeling of discomfort</td>\n",
       "      <td>fatigue or a general feeling of discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68144</th>\n",
       "      <td>68144</td>\n",
       "      <td>i have fatigue or a general feeling of discomfort</td>\n",
       "      <td>fatigue or a general feeling of discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68145</th>\n",
       "      <td>68145</td>\n",
       "      <td>i have fatigue or a general feeling of discomfort</td>\n",
       "      <td>fatigue or a general feeling of discomfort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68146 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          Questions  \\\n",
       "0               0                      i'm fine. how about yourself?   \n",
       "1               1                i'm pretty good. thanks for asking.   \n",
       "2               2                  no problem. so how have you been?   \n",
       "3               3                   i've been great. what about you?   \n",
       "4               4           i've been good. i'm in school right now.   \n",
       "...           ...                                                ...   \n",
       "68141       68141  i have fatigue or a general feeling of discomfort   \n",
       "68142       68142  i have fatigue or a general feeling of discomfort   \n",
       "68143       68143  i have fatigue or a general feeling of discomfort   \n",
       "68144       68144  i have fatigue or a general feeling of discomfort   \n",
       "68145       68145  i have fatigue or a general feeling of discomfort   \n",
       "\n",
       "                                          Answers  \n",
       "0             i'm pretty good. thanks for asking.  \n",
       "1               no problem. so how have you been?  \n",
       "2                i've been great. what about you?  \n",
       "3        i've been good. i'm in school right now.  \n",
       "4                       what school do you go to?  \n",
       "...                                           ...  \n",
       "68141  fatigue or a general feeling of discomfort  \n",
       "68142  fatigue or a general feeling of discomfort  \n",
       "68143  fatigue or a general feeling of discomfort  \n",
       "68144  fatigue or a general feeling of discomfort  \n",
       "68145  fatigue or a general feeling of discomfort  \n",
       "\n",
       "[68146 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca69900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(x):\n",
    "    return [a for a in (''.join([a for a in x if a not in string.punctuation])).lower()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a247d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('classifier',DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b1240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(query):\n",
    "    return lemmatizer.lemmatize(query)\n",
    "    \n",
    "    \n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "df['Questions2'] = df['Questions'].apply(cleaner)\n",
    "\n",
    "#df['Questions2'] = df['Questions'].apply(cleanText)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce850b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f79cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('classifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipe.fit(df['Questions'],df['Answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fc8c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sss\n"
     ]
    }
   ],
   "source": [
    "print('sss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a35d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe2=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64725402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:hi\n",
      "bot:  hello\n",
      "user:recommend me a cure fo acne\n",
      "bot:  0- A CN Gel(Topical) 20gmA CN Soap 75gm is used for Mild to moderate acne (spots)\n",
      "1- A Ret 0.05% Gel 20gmA Ret 0.1% Gel 20gmA Ret 0.025% Gel 20gm is used for A RET 0.025% is a prescription medicine that is used to reduce fine wrinkles\n",
      "2- ACGEL CL NANO Gel 15gm is used for It is used to treat acne vulgaris in people 12 years of age and older. Acne vulgaris is a condition in which the skin has blackheads, white heads and pimple\n",
      "3- ACGEL NANO Gel 15gm is used for It is used to treat acne vulgaris in people 12 years of age and older. Acne vulgaris is a condition in which the skin has blackheads, white heads and pimple\n",
      "4- Acleen 1% Lotion 25ml is used for treat the most severe form of acne (nodular acne)Â \n",
      "5- Aclene 0.10% Gel 15gm is used for treat the most severe form of acne (nodular acne)Â \n",
      "6- Acnay Gel 10gm is used for treat the most severe form of acne (nodular acne)Â \n",
      "7- Acne Aid Bar 50gmAcne Aid Bar 100gm is used for Â treat acne vulgarisÂ \n",
      "8- Acne UV Gel 60gm is used for Â treat acne vulgarisÂ \n",
      "9- Acne UV SPF 30 Gel 30gm is used for Â treat mild to moderate acne(spots)\n",
      "\n",
      "user:exit\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    qu = input('user:' )\n",
    "    if(qu=='exit'):\n",
    "        break\n",
    "    \n",
    "    print('bot: ',Pipe2.predict([qu])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55115c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symp.index('acid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb3c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
